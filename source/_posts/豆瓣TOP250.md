---
title: 豆瓣TOP250
date: 2018-12-29 17:07:00
categories: Python
tags:
  - python
  - 爬虫
---
#  豆瓣TOP250
## 前言
>记得当初去参加大数据比赛的时候有个环节是对数据清洗。你可以理解前期已经是做好了，你只需要后期，针对已经获得的数据进行分析。里面就有对电影分析的，还需要针对获取的数据进行作图（matplotlib）。想尝试自己去爬数据并对数据进行清洗分析统计。  
## 1. 网页分析
 站点：[豆瓣电影 Top 250](https://movie.douban.com/top250)
 并不像爬B站那个一样只需要针对请求API获得的json进行分析。我们需要针对网页（HTML）进行分析，有一个神器登场（Beautiful Soup）。可以从HTML，XML中提取数据的python模块。

### 1.1获取网页
```python
# -*- conding:utf-8 -*-
import requests 

def get_html(url):
    try:
        req = requests.get(url)
        req.encoding = 'utf-8'
        if req.status_code == 200 :
            data = req.text
        else:
            print "[-] "+url +" error" 
    except Exception,e:
        print e
if __name__ == "__main__":
    douban_url = "https://movie.douban.com/top250"
    get_html(douban_url)
```
#### 如果你想尝试print？？？ stop!!! 你绝对报错的。
```
'gbk' codec can't encode character u'\xee' in position 21861: illegal multibyte sequence
```
 编码这个东西很玄学的，我也很好奇，网易一般就是UTF-8，我还encode了它？但是还是不行。网上的猜测都是说“本身Unicode类型的字符中，包含了一些无法转换为GBK编码的一些字符。”没关系我们并不需要print出来去看html，浏览器没有更方便？
### 1.2 分析网页
[![](https://image.kalifun.top/upload/1812/9a4fd4c4917b0dc3.png)](https://image.kalifun.top/upload/1812/9a4fd4c4917b0dc3.png)
其实可用的信息很多，根据自己想实现的效果来获取具体的信息。
[![](https://image.kalifun.top/upload/1812/d86ddf15e5c3d67f.png)](https://image.kalifun.top/upload/1812/d86ddf15e5c3d67f.png)
 你会发现整个关于电影的是在ol这个标签里，所以我们所需要这个标签里的代码。
```python
allmovie = soup.find(name='ol',class_='grid_view')
```
 看图片可以看懂每一个电影的信息都在li的标签里。
```python
movielist = allmovie.find_all(name='li')
```
## 2.使用beautifulsoup
contents
 根据文档树进行搜索，返回标记对象（tag）的列表,注意，直接.contents，返回的是列表，不是单一元素。使用contents向后遍历树，使用parent向前遍历树
```python
    soup = BeautifulSoup(data,'html.parser')
    all_content = soup.find(name='ol',class_='grid_view')
    all_movies = all_content.find_all(name='li')
    for single in all_movies:
        top_num = single.find(name='em').string
        title = single.find_all(name='span',class_='title')
        chiness_name = title[0].string
        class_bd = single.find(name='div',class_='bd').contents
        movie_yearth = re.findall(r'\d{4}',str(class_bd[1]))[0]
        movie_rating = re.findall(r'\d?\.\d',str(class_bd[3]))[0]
        movie_country = re.findall(r'\d{4}.*$/',str(class_bd[1]))
        movie_eval = class_bd[3].find_all(name='span')[-1]  
```
后续我将html保存到文件中，这样应该可以解决编码报错的问题。